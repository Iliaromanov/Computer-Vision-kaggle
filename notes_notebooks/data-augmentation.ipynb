{"cells":[{"cell_type":"markdown","metadata":{},"source":"<!--TITLE:Data Augmentation-->\n\n# Introduction #\n\nNow that you've learned the fundamentals of convolutional classifiers, you're ready to move on to more advanced topics.\n\nIn this lesson, you'll learn a trick that can give a boost to your image classifiers: it's called **data augmentation**. "},{"cell_type":"markdown","metadata":{},"source":"# The Usefulness of Fake Data #\n\nThe best way to improve the performance of a machine learning model is to train it on more data. The more examples the model has to learn from, the better it will be able to recognize which differences in images matter and which do not. More data helps the model to *generalize* better.\n\nOne easy way of getting more data is to use the data you already have. If we can transform the images in our dataset in ways that preserve the class, we can teach our classifier to ignore those kinds of transformations. For instance, whether a car is facing left or right in a photo doesn't change the fact that it is a *Car* and not a *Truck*. So, if we **augment** our training data with flipped images, our classifier will learn that \"left or right\" is a difference it should ignore.\n\nAnd that's the whole idea behind data augmentation: add in some extra fake data that looks reasonably like the real data and your classifier will improve.\n\n# Using Data Augmentation #\n\nTypically, many kinds of transformation are used when augmenting a dataset. These might include rotating the image, adjusting the color or contrast, warping the image, or many other things, usually applied in combination. Here is a sample of the different ways a single image might be transformed.\n\n<figure>\n<img src=\"https://i.imgur.com/UaOm0ms.png\" width=400, alt=\"Sixteen transformations of a single image of a car.\">\n</figure>\n\nData augmentation is usually done *online*, meaning, as the images are being fed into the network for training. Recall that training is usually done on mini-batches of data. This is what a batch of 16 images might look like when data augmentation is used.\n\n<figure>\n<img src=\"https://i.imgur.com/MFviYoE.png\" width=400, alt=\"A batch of 16 images with various random transformations applied.\">\n</figure>\n\nEach time an image is used during training, a new random transformation is applied. This way, the model is always seeing something a little different than what it's seen before. This extra variance in the training data is what helps the model on new data.\n\nIt's important to remember though that not every transformation will be useful on a given problem. Most importantly, whatever transformations you use should not mix up the classes. If you were training a [digit recognizer](https://www.kaggle.com/c/digit-recognizer), for instance, rotating images would mix up '9's and '6's. In the end, the best approach for finding good augmentations is the same as with most ML problems: try it and see!\n\n# Example - Training with Data Augmentation #\n\nKeras lets you augment your data in two ways. The first way is to include it in the data pipeline with a function like [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator). The second way is to include it in the model definition by using Keras's **preprocessing layers**. This is the approach that we'll take. The primary advantage for us is that the image transformations will be computed on the GPU instead of the CPU, potentially speeding up training.\n\nIn this exercise, we'll learn how to improve the classifier from Lesson 1 through data augmentation. This next hidden cell sets up the data pipeline."},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"\n# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Reproducability\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n"},{"cell_type":"markdown","metadata":{},"source":"## Step 2 - Define Model ##\n\nTo illustrate the effect of augmentation, we'll just add a couple of simple transformations to the model from Tutorial 1."},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n# these are a new feature in TF 2.2\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\npretrained_base = tf.keras.models.load_model(\n    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n)\npretrained_base.trainable = False\n\nmodel = keras.Sequential([\n    # Preprocessing\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5), # contrast change by up to 50%\n    # Base\n    pretrained_base,\n    # Head\n    layers.Flatten(),\n    layers.Dense(6, activation='relu'),\n    layers.Dense(1, activation='sigmoid'),\n])"},{"cell_type":"markdown","metadata":{},"source":"## Step 3 - Train and Evaluate ##\n\nAnd now we'll start the training!"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=30,\n    verbose=0,\n)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pandas as pd\n\nhistory_frame = pd.DataFrame(history.history)\n\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"},{"cell_type":"markdown","metadata":{},"source":"The training and validation curves in the model from Tutorial 1 diverged fairly quickly, suggesting that it could benefit from some regularization. The learning curves for this model were able to stay closer together, and we achieved some modest improvement in validation loss and accuracy. This suggests that the dataset did indeed benefit from the augmentation.\n\n# Your Turn #\n\nMove on to the [**Exercise**](https://www.kaggle.com/kernels/fork/11991328) to apply data augmentation to the custom convnet you built in Lesson 5. This will be your best model ever!"},{"cell_type":"markdown","metadata":{},"source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/196537) to chat with other Learners.*"}],"metadata":{"jupytext":{"formats":"md,ipynb"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}